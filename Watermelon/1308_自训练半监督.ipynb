{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自训练半监督"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/vivian_ll/article/details/103494042?utm_medium=distribute.pc_relevant.none-task-blog-title-2&spm=1001.2101.3001.4242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面以XGBoost作为基分类器为例，自己写一个自训练半监督算法：\n",
    "\n",
    "数据全部是有标注的，从中随机挑选一定比例（ratio）的数据丢弃标注，作为无标注数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description='BMD prediction')\n",
    "parser.add_argument('--classifier-name', type=str, default='xgboost', metavar='S',\n",
    "                    help='model name')\n",
    "parser.add_argument('--dataset', type=str, default='../data/newdata/largedata.csv', metavar='DATASET',\n",
    "                    help='dataset path')\n",
    "parser.add_argument('--feature-columns', nargs='+', default=['sex','year','height','weight'],\n",
    "                    help='columns of features')\n",
    "parser.add_argument('--label-column', type=str, default='label',\n",
    "                    help='column of label')\n",
    "parser.add_argument('--cat-numbers', type=int, default=2,\n",
    "                    help='Number of categories')\n",
    "parser.add_argument('--model-name', type=str, default='xgboost', choices=['xgboost','svm'],\n",
    "                    help='name of classifier')\n",
    "parser.add_argument('--save-path', type=str, default='../model/classifiers/xgboost_label_gridSearch.joblib.dat',\n",
    "                    help='path of saved model')\n",
    "parser.add_argument('--grid-search', type=bool, default=True,\n",
    "                    help='adjust parameters with grid search')\n",
    "\n",
    "def read_data(args):\n",
    "    path = args.dataset\n",
    "    data = pd.read_csv(path,encoding='gbk')\n",
    "\n",
    "    # 获取label列非空的行\n",
    "    for i in range(len(data)):\n",
    "        if np.isnan(data[args.label_column][i]):\n",
    "            data = data.drop(i)\n",
    "    # data.to_csv('data.csv')\n",
    "    # data.info()\n",
    "    return data\n",
    "\n",
    "def split(args,data):\n",
    "    features = data[args.feature_columns]\n",
    "    label = data[args.label_column]\n",
    "    print(args.feature_columns)\n",
    "    print(args.label_column)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,label,test_size=0.2, random_state=77)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.transform(X_test)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def selfTraining(args, X_train, X_test, y_train, y_test):\n",
    "    ratio = 0.1  # 缺失值比例\n",
    "    rng = np.random.RandomState(10)  # 产生一个随机状态种子\n",
    "\n",
    "    YSemi_train = np.copy(y_train)\n",
    "    YSemi_train[rng.rand(len(y_train)) < ratio] = -1    # rng.rand()返回一个或一组服从“0~1”均匀分布的随机样本值\n",
    "\n",
    "    unlabeledX = X_train[YSemi_train == -1, :]\n",
    "    YTrue = y_train[YSemi_train == -1]\n",
    "\n",
    "    idx = np.where(YSemi_train != -1)[0]   # np.where返回一个(array([   3,   10,   12, ..., 8042, 8050, 8053], dtype=int64),)\n",
    "    labeledX = X_train[idx, :]\n",
    "    labeledY = YSemi_train[idx]\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        learning_rate=0.02,\n",
    "        n_estimators=90,\n",
    "        max_depth=4,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=1,\n",
    "        colsample_bytree=1,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27\n",
    "    )\n",
    "\n",
    "    # 全监督\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    score = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_score = accuracy_score(y_test, clf.predict(X_test))   # 测试集准确率\n",
    "    auc_score = roc_auc_score(y_test, clf.predict(X_test))\n",
    "    f1 = f1_score(y_test, clf.predict(X_test))\n",
    "    print(\"Training data size=\", len(y_train), \"Labeld accuracy= %.4f\" % score, \" , Unlabeled ratio=\", 0,\n",
    "          \"ACC: %.4f\" % test_score, 'AUC: %.4f' % auc_score, 'F1-score: %.4f' % f1)\n",
    "\n",
    "    # 半监督\n",
    "    clf = model.fit(labeledX, labeledY)\n",
    "    unlabeledY = clf.predict(unlabeledX)\n",
    "    print(unlabeledY)\n",
    "    unlabeledProb = clf.predict_proba(unlabeledX).max(axis=1)  # 预测为0和1的置信度，取大的\n",
    "    print(unlabeledProb)\n",
    "    ratioInitial = 1 - (len(labeledY) / len(y_train))\n",
    "    score = accuracy_score(labeledY, clf.predict(labeledX))\n",
    "    test_score = accuracy_score(y_test, clf.predict(X_test))\n",
    "    auc_score = roc_auc_score(y_test, clf.predict(X_test))\n",
    "    f1 = f1_score(y_test, clf.predict(X_test))\n",
    "    print(\"iteration=\",0, \"Training data size=\", len(labeledY), \"Labeld accuracy=:  %.4f\" % score, \" , Unlabeled ratio=:  %.4f\" % ratioInitial, \"ACC: %.4f\" % test_score, 'AUC: %.4f' % auc_score, 'F1-score: %.4f' % f1)\n",
    "\n",
    "    max_iter = 500\n",
    "    probThreshold = 0.8\n",
    "\n",
    "    unlabeledXOrg = np.copy(unlabeledX)\n",
    "    YTrueOrg = np.copy(YTrue)\n",
    "\n",
    "    rr = []\n",
    "    it = []\n",
    "\n",
    "    i = 0\n",
    "    repeat = 1\n",
    "\n",
    "\n",
    "    while (i < max_iter and score > 0.01 and repeat<=10):\n",
    "\n",
    "        lastscore = score\n",
    "        ratio = 1 - (len(labeledY) / len(y_train))\n",
    "\n",
    "        rr.append(ratio)\n",
    "        it.append(i)\n",
    "\n",
    "        labelidx = np.where(unlabeledProb > probThreshold)[0]\n",
    "        unlabelidx = np.where(unlabeledProb <= probThreshold)[0]\n",
    "\n",
    "        labeledX = np.vstack((labeledX, unlabeledX[labelidx, :]))  # 按照行顺序把数组给堆叠起来\n",
    "        labeledY = np.hstack((labeledY, unlabeledY[labelidx]))\n",
    "        unlabeledX = unlabeledX[unlabelidx, :]\n",
    "        YTrue = y_train[unlabelidx]\n",
    "\n",
    "        clf = model.fit(labeledX, labeledY)\n",
    "        score = accuracy_score(labeledY, clf.predict(labeledX))\n",
    "        test_score = accuracy_score(y_test, clf.predict(X_test))\n",
    "        auc_score = roc_auc_score(y_test, clf.predict(X_test))\n",
    "        f1 = f1_score(y_test, clf.predict(X_test))\n",
    "        print(\"iteration=\",i+1, \"Training data size=\", len(labeledY), \"Labeld accuracy= %.4f\" % score, \" , Unlabeled ratio= %.4f\" % ratio, \"ACC: %.4f\" % test_score, 'AUC: %.4f' % auc_score, 'F1-score: %.4f' % f1)\n",
    "\n",
    "        unlabeledY = clf.predict(unlabeledX)\n",
    "        unlabeledProb = clf.predict_proba(unlabeledX).max(axis=1)\n",
    "\n",
    "        i += 1\n",
    "        if lastscore == score:\n",
    "            repeat += 1\n",
    "        else:\n",
    "            repeat = 1\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data = read_data(args)\n",
    "    X_train, X_test, y_train, y_test = split(args,data)\n",
    "\n",
    "    selfTraining(args, np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main(parser.parse_args())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
